{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING: https://arxiv.org/pdf/1509.02971\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\", continuous=True, render_mode='human')\n",
    "\n",
    "# Get the state and action sizes\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.shape[0]\n",
    "\n",
    "print(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(state[\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m, state_size])\n\u001b[1;32m      3\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/gym/wrappers/time_limit.py:68\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py:42\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/gym/wrappers/env_checker.py:45\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_reset_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:192\u001b[0m, in \u001b[0;36menv_reset_passive_checker\u001b[0;34m(env, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFuture gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    195\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/gym/envs/box2d/lunar_lander.py:419\u001b[0m, in \u001b[0;36mLunarLander.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawlist \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlander] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegs\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m], {}\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/gym/envs/box2d/lunar_lander.py:710\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen\u001b[38;5;241m.\u001b[39mblit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    709\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state = np.reshape(state[0], [1, state_size])\n",
    "done = False\n",
    "score = 0\n",
    "for i in range(100):\n",
    "    env.render()\n",
    "    # select action\n",
    "    action = np.random.uniform(low=-1, high=1, size=(4,))\n",
    "    # perform the action\n",
    "    next_state, reward, done, _, _= env.step(action)\n",
    "    # update the score\n",
    "    score += reward\n",
    "    # move to the next state\n",
    "    next_state = np.reshape(next_state, [1, state_size])\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_size, action_size,\n",
    "                 lr_actor=0.001, lr_critic=0.001,\n",
    "                 gamma=0.95, batch_size=32,\n",
    "                 buffer_size=10**6, min_start=10000) -> None:\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        self.buffer = deque(maxlen=self.buffer_size)\n",
    "        self.min_start = min_start\n",
    "        \n",
    "        self.lr_actor = lr_actor\n",
    "        self.lr_critic = lr_critic\n",
    "        \n",
    "        self.actor_main = self.build_actor_network()\n",
    "        self.actor_target = self.build_actor_network()\n",
    "        \n",
    "        self.critic_main = self.build_critic_network()\n",
    "        self.critic_target = self.build_critic_network()\n",
    "        \n",
    "        self.update_target(tau=1.0)\n",
    "        \n",
    "        self.opt_actor = tf.keras.optimizers.legacy.Adam(learning_rate=self.lr_actor)\n",
    "        self.opt_critic = tf.keras.optimizers.legacy.Adam(learning_rate=self.lr_critic)\n",
    "        \n",
    "        self.min_action = -1\n",
    "        self.max_action = 1\n",
    "        \n",
    "        self.train_step = 0\n",
    "        self.replace_step = 100\n",
    "\n",
    "\n",
    "    def build_actor_network(self):\n",
    "        \"\"\"\n",
    "        The actor network\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(self.action_size, activation='tanh'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_critic_network(self):\n",
    "        \"\"\"\n",
    "        The critic network used for estimating the value function\n",
    "        The input is [state, action], output is the Q(s, a)\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=self.state_size + self.action_size, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def select_action(self, state, evaluate=False):\n",
    "        \"\"\"\n",
    "        Return the action value based on the input state\n",
    "\n",
    "        evaluate (bool, optional): False for training, True for testing.\n",
    "        \"\"\"\n",
    "        actions = self.actor_main(state)\n",
    "        if not evaluate:\n",
    "            # we add noise for exploration\n",
    "            actions += np.random.normal(0, 0.2, (1, action_size))\n",
    "        # we clip it since it might be out of range after adding noise\n",
    "        actions = np.clip(actions, self.min_action, self.max_action)\n",
    "        \n",
    "        return actions[0]\n",
    "    \n",
    "    def store_data(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Store data into the buffer.\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.min_start:\n",
    "            print(\"Collect enough samples, training starting\")\n",
    "        # Append the new data to the buffer\n",
    "        self.buffer.append([state, action, reward, next_state, done])\n",
    "    \n",
    "    def update_target(self, tau=0.005):\n",
    "        \"\"\"\n",
    "        Updae the target model using soft update.\n",
    "        \"\"\"\n",
    "        # Iterate through the weights of the target and main models\n",
    "        for target_weights, main_weights in zip(self.actor_target.weights, self.actor_main.weights):\n",
    "            # Update the target model weights with a soft update\n",
    "            target_weights.assign(tau * main_weights + (1 - tau) * target_weights)\n",
    "        \n",
    "        for target_weights, main_weights in zip(self.critic_target.weights, self.critic_main.weights):\n",
    "            # Update the target model weights with a soft update\n",
    "            target_weights.assign(tau * main_weights + (1 - tau) * target_weights)\n",
    "\n",
    "    \n",
    "    def learn(self):\n",
    "        if len(self.buffer) < self.min_start:\n",
    "            return\n",
    "        # sample a minibatch from the buffer\n",
    "        minibatch = random.sample(self.buffer, min(self.buffer_size, self.batch_size))\n",
    "        states, actions, rewards, next_states, dones = [tf.convert_to_tensor(x, dtype=tf.float32) for x in zip(*minibatch)]\n",
    "\n",
    "        with tf.GradientTape() as tape1:\n",
    "            actions_next_states = self.actor_target(tf.squeeze(next_states))\n",
    "            Q_value_next_states = tf.squeeze(self.critic_target(tf.concat([tf.squeeze(next_states), actions_next_states], axis=1)))\n",
    "            y = rewards + self.gamma * Q_value_next_states * (1 - dones)\n",
    "            \n",
    "            Q_value_current_states = tf.squeeze(self.critic_main(tf.concat([tf.squeeze(states), actions], axis=1)))\n",
    "            critic_loss = tf.reduce_mean(tf.square(y - Q_value_current_states))\n",
    "            \n",
    "        with tf.GradientTape() as tape2:\n",
    "            new_actions = self.actor_main(tf.squeeze(states))\n",
    "            actor_loss = tf.squeeze(self.critic_main(tf.concat([tf.squeeze(states), new_actions], axis=1)))\n",
    "            actor_loss = - tf.reduce_mean(actor_loss)\n",
    "        \n",
    "        grads1 = tape1.gradient(critic_loss, self.critic_main.trainable_variables)\n",
    "        self.opt_critic.apply_gradients(zip(grads1, self.critic_main.trainable_variables))\n",
    "        \n",
    "        grads2 = tape2.gradient(actor_loss, self.actor_main.trainable_variables)\n",
    "        self.opt_actor.apply_gradients(zip(grads2, self.actor_main.trainable_variables))\n",
    "        \n",
    "        if self.train_step % self.replace_step == 0:\n",
    "            self.update_target()\n",
    "        self.train_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 - score  -452.4157179934169 - average score  -452.4157179934169 - buffer size 121 - timestep  121\n",
      "Episode  1 - score  -52.98986070397111 - average score  -252.70278934869398 - buffer size 232 - timestep  111\n",
      "Episode  2 - score  -303.3476710884797 - average score  -269.5844165952892 - buffer size 339 - timestep  107\n",
      "Episode  3 - score  -506.41198045618205 - average score  -328.79130756051245 - buffer size 469 - timestep  130\n",
      "Episode  4 - score  -39.77006577747293 - average score  -270.98705920390455 - buffer size 569 - timestep  100\n",
      "Episode  5 - score  -484.5778481870514 - average score  -306.585524034429 - buffer size 947 - timestep  378\n",
      "Episode  6 - score  -481.7832219762043 - average score  -331.6137665975398 - buffer size 1069 - timestep  122\n",
      "Episode  7 - score  -386.36355233068485 - average score  -338.45748981418285 - buffer size 1156 - timestep  87\n",
      "Episode  8 - score  -326.27083898432653 - average score  -337.10341749975436 - buffer size 1266 - timestep  110\n",
      "Episode  9 - score  -350.2728699138477 - average score  -338.42036274116373 - buffer size 1348 - timestep  82\n",
      "Episode  10 - score  -193.58455155975014 - average score  -325.25347081558067 - buffer size 1469 - timestep  121\n",
      "Episode  11 - score  -380.84668674883676 - average score  -329.8862388100187 - buffer size 1627 - timestep  158\n",
      "Episode  12 - score  -85.26476316095349 - average score  -311.06920222162904 - buffer size 1758 - timestep  131\n",
      "Episode  13 - score  -72.42665438292696 - average score  -294.0233059474361 - buffer size 2090 - timestep  332\n",
      "Episode  14 - score  -466.05262570060705 - average score  -305.4919272643141 - buffer size 2236 - timestep  146\n",
      "Episode  15 - score  -251.9520988657806 - average score  -302.1456879894058 - buffer size 2339 - timestep  103\n",
      "Episode  16 - score  -49.09798158925541 - average score  -287.260528789397 - buffer size 2633 - timestep  294\n",
      "Episode  17 - score  -376.6155455572105 - average score  -292.22469638760884 - buffer size 2728 - timestep  95\n",
      "Episode  18 - score  -62.25156652060636 - average score  -280.1208474472403 - buffer size 2886 - timestep  158\n",
      "Episode  19 - score  -398.58434580086083 - average score  -286.0440223649213 - buffer size 3027 - timestep  141\n",
      "Episode  20 - score  -329.4933715249115 - average score  -288.11303899158753 - buffer size 3114 - timestep  87\n",
      "Episode  21 - score  -272.75286375824123 - average score  -287.4148492082536 - buffer size 3217 - timestep  103\n",
      "Episode  22 - score  -302.0014760641567 - average score  -288.0490503759016 - buffer size 3311 - timestep  94\n",
      "Episode  23 - score  -267.2900793755874 - average score  -287.18409325088845 - buffer size 3471 - timestep  160\n",
      "Episode  24 - score  -135.32314821666137 - average score  -281.1096554495193 - buffer size 3587 - timestep  116\n",
      "Episode  25 - score  -266.49396201037956 - average score  -280.5475133941678 - buffer size 3711 - timestep  124\n",
      "Episode  26 - score  -245.72873029462676 - average score  -279.25792883492556 - buffer size 3830 - timestep  119\n",
      "Episode  27 - score  -284.6602841134932 - average score  -279.4508700948744 - buffer size 3922 - timestep  92\n",
      "Episode  28 - score  -302.2775717549782 - average score  -280.23799773832627 - buffer size 4024 - timestep  102\n",
      "Episode  29 - score  -277.4009563270911 - average score  -280.14342969128506 - buffer size 4201 - timestep  177\n",
      "Episode  30 - score  -403.09751519598575 - average score  -284.10969051401736 - buffer size 4286 - timestep  85\n",
      "Episode  31 - score  -318.2027752547452 - average score  -285.17509941216514 - buffer size 4420 - timestep  134\n",
      "Episode  32 - score  -432.2568673165818 - average score  -289.63212268199595 - buffer size 4536 - timestep  116\n",
      "Episode  33 - score  -37.54698695101474 - average score  -282.2178539840259 - buffer size 4673 - timestep  137\n",
      "Episode  34 - score  -302.1571965471523 - average score  -282.7875494858295 - buffer size 4775 - timestep  102\n",
      "Episode  35 - score  -268.74396593884353 - average score  -282.3974499428577 - buffer size 4898 - timestep  123\n",
      "Episode  36 - score  -479.06538052790575 - average score  -287.71279941812924 - buffer size 5053 - timestep  155\n",
      "Episode  37 - score  -396.9862321857649 - average score  -290.58841606990916 - buffer size 5143 - timestep  90\n",
      "Episode  38 - score  -321.2382232809265 - average score  -291.3743085624993 - buffer size 5253 - timestep  110\n",
      "Episode  39 - score  -86.89700234476044 - average score  -286.26237590705585 - buffer size 5339 - timestep  86\n",
      "Episode  40 - score  -183.60989382114997 - average score  -283.7586568317899 - buffer size 5502 - timestep  163\n",
      "Episode  41 - score  -66.24193602692041 - average score  -278.5796872888168 - buffer size 5635 - timestep  133\n",
      "Episode  42 - score  -329.161872578528 - average score  -279.7560171792752 - buffer size 5720 - timestep  85\n",
      "Episode  43 - score  -290.51264868388955 - average score  -280.0004860771073 - buffer size 5900 - timestep  180\n",
      "Episode  44 - score  -380.2480992903501 - average score  -282.22821081517935 - buffer size 5992 - timestep  92\n",
      "Episode  45 - score  -220.26867376108828 - average score  -280.8812643574817 - buffer size 6121 - timestep  129\n",
      "Episode  46 - score  -305.18560879183826 - average score  -281.398378068851 - buffer size 6230 - timestep  109\n",
      "Episode  47 - score  -358.30223522790635 - average score  -283.00054175966466 - buffer size 6459 - timestep  229\n",
      "Episode  48 - score  -111.2479002700009 - average score  -279.495385810896 - buffer size 6627 - timestep  168\n",
      "Episode  49 - score  -272.8075356424187 - average score  -279.3616288075264 - buffer size 6751 - timestep  124\n",
      "Episode  50 - score  14.774418863981396 - average score  -273.5942553237714 - buffer size 6894 - timestep  143\n",
      "Episode  51 - score  -461.09715703660663 - average score  -277.20008035671054 - buffer size 7139 - timestep  245\n",
      "Episode  52 - score  -257.3849675036736 - average score  -276.82621030287964 - buffer size 7233 - timestep  94\n",
      "Episode  53 - score  -329.2823911871886 - average score  -277.7976210599965 - buffer size 7382 - timestep  149\n",
      "Episode  54 - score  -408.8166384804214 - average score  -280.1797850130951 - buffer size 7474 - timestep  92\n",
      "Episode  55 - score  -325.4121914524634 - average score  -280.9875065566553 - buffer size 7580 - timestep  106\n",
      "Episode  56 - score  -436.2026017433645 - average score  -283.71057840203616 - buffer size 7734 - timestep  154\n",
      "Episode  57 - score  -18.67157079793563 - average score  -279.1409403398965 - buffer size 7842 - timestep  108\n",
      "Episode  58 - score  -420.45198275491737 - average score  -281.5360427537104 - buffer size 7963 - timestep  121\n",
      "Episode  59 - score  -297.26725644063924 - average score  -281.7982296484925 - buffer size 8072 - timestep  109\n",
      "Episode  60 - score  -382.9653858768332 - average score  -283.4567076194489 - buffer size 8267 - timestep  195\n",
      "Episode  61 - score  -258.9673977780809 - average score  -283.06171875103973 - buffer size 8375 - timestep  108\n",
      "Episode  62 - score  -50.51426378129654 - average score  -279.37048930707556 - buffer size 8501 - timestep  126\n",
      "Episode  63 - score  -233.21592651233124 - average score  -278.6493242634077 - buffer size 8641 - timestep  140\n",
      "Collect enough samples, training starting\n",
      "Episode  64 - score  21.165770883205056 - average score  -274.0367843380752 - buffer size 10902 - timestep  2261\n",
      "Episode  65 - score  -443.13458002600544 - average score  -276.59887215152867 - buffer size 10962 - timestep  60\n",
      "Episode  66 - score  -581.8660248772496 - average score  -281.1550983116141 - buffer size 11026 - timestep  64\n",
      "Episode  67 - score  -391.71757344926505 - average score  -282.7810170636384 - buffer size 11078 - timestep  52\n",
      "Episode  68 - score  -614.5010346877569 - average score  -287.5885535509445 - buffer size 11144 - timestep  66\n",
      "Episode  69 - score  -589.1387640789142 - average score  -291.89641370134404 - buffer size 11210 - timestep  66\n",
      "Episode  70 - score  -402.7077073570241 - average score  -293.4571361471987 - buffer size 11341 - timestep  131\n",
      "Episode  71 - score  -212.196776467475 - average score  -292.3285200405358 - buffer size 11415 - timestep  74\n",
      "Episode  72 - score  -389.97638755511093 - average score  -293.6661620612834 - buffer size 11494 - timestep  79\n",
      "Episode  73 - score  -611.097808635405 - average score  -297.95577890687963 - buffer size 11645 - timestep  151\n",
      "Episode  74 - score  -524.653482579947 - average score  -300.97841495585385 - buffer size 11734 - timestep  89\n",
      "Episode  75 - score  -362.55705857845635 - average score  -301.78866026667754 - buffer size 11834 - timestep  100\n",
      "Episode  76 - score  -358.5424864484354 - average score  -302.5257229443627 - buffer size 11967 - timestep  133\n",
      "Episode  77 - score  -246.63799938137424 - average score  -301.80921366791415 - buffer size 12087 - timestep  120\n",
      "Episode  78 - score  -206.86376735621403 - average score  -300.607372575361 - buffer size 12214 - timestep  127\n",
      "Episode  79 - score  -1000.4689146538935 - average score  -309.35564185134274 - buffer size 12406 - timestep  192\n",
      "Episode  80 - score  -277.0424762313419 - average score  -308.95671388072543 - buffer size 12563 - timestep  157\n",
      "Episode  81 - score  -176.0400364495127 - average score  -307.3357787901009 - buffer size 12666 - timestep  103\n",
      "Episode  82 - score  -398.2239186104137 - average score  -308.4308166192613 - buffer size 12782 - timestep  116\n",
      "Episode  83 - score  -396.51823953889743 - average score  -309.4794764159236 - buffer size 12990 - timestep  208\n",
      "Episode  84 - score  -386.99635288806314 - average score  -310.39143966853703 - buffer size 13144 - timestep  154\n",
      "Episode  85 - score  -230.3922443726206 - average score  -309.4612164674217 - buffer size 13342 - timestep  198\n",
      "Episode  86 - score  -392.3969948576862 - average score  -310.41450127650523 - buffer size 13467 - timestep  125\n",
      "Episode  87 - score  -633.8670567885597 - average score  -314.0900984982331 - buffer size 13548 - timestep  81\n",
      "Episode  88 - score  -324.8239891188826 - average score  -314.21070401082466 - buffer size 13644 - timestep  96\n",
      "Episode  89 - score  -565.998513811903 - average score  -317.0083463419478 - buffer size 13720 - timestep  76\n",
      "Episode  90 - score  -304.09973002789354 - average score  -316.8664934154197 - buffer size 13896 - timestep  176\n",
      "Episode  91 - score  -626.4340657196237 - average score  -320.23135833176974 - buffer size 14125 - timestep  229\n",
      "Episode  92 - score  -429.36278303967276 - average score  -321.4048145114246 - buffer size 14278 - timestep  153\n",
      "Episode  93 - score  -770.429816403479 - average score  -326.18167623368055 - buffer size 14367 - timestep  89\n",
      "Episode  94 - score  -556.5677327574936 - average score  -328.6067926181417 - buffer size 14532 - timestep  165\n",
      "Episode  95 - score  -696.7557158450999 - average score  -332.4416772350892 - buffer size 14693 - timestep  161\n",
      "Episode  96 - score  -425.60462208321474 - average score  -333.4021199654822 - buffer size 14816 - timestep  123\n",
      "Episode  97 - score  -576.4216465490979 - average score  -335.8819110530701 - buffer size 14953 - timestep  137\n",
      "Episode  98 - score  -895.4039520642256 - average score  -341.53364884106156 - buffer size 15152 - timestep  199\n",
      "Episode  99 - score  -894.5674665803944 - average score  -347.06398701845495 - buffer size 15385 - timestep  233\n",
      "Episode  100 - score  -728.3973254030464 - average score  -349.8238030925513 - buffer size 15496 - timestep  111\n",
      "Episode  101 - score  -678.6252991077431 - average score  -356.080157476589 - buffer size 15633 - timestep  137\n",
      "Episode  102 - score  -1147.8570233780065 - average score  -364.5252509994842 - buffer size 15737 - timestep  104\n",
      "Episode  103 - score  -998.6204755316336 - average score  -369.4473359502387 - buffer size 15846 - timestep  109\n",
      "Episode  104 - score  -875.1930854861743 - average score  -377.8015661473257 - buffer size 16053 - timestep  207\n",
      "Episode  105 - score  -1067.2932200869818 - average score  -383.62871986632507 - buffer size 16212 - timestep  159\n",
      "Episode  106 - score  -815.9863253350559 - average score  -386.9707508999135 - buffer size 16377 - timestep  165\n",
      "Episode  107 - score  -973.3377419264871 - average score  -392.8404927958716 - buffer size 16474 - timestep  97\n",
      "Episode  108 - score  -992.6067448983868 - average score  -399.50385185501216 - buffer size 16573 - timestep  99\n",
      "Episode  109 - score  -1049.6515283901763 - average score  -406.49763843977547 - buffer size 16764 - timestep  191\n",
      "Episode  110 - score  -689.8715332366038 - average score  -411.46050825654396 - buffer size 16926 - timestep  162\n",
      "Episode  111 - score  -870.4503420719653 - average score  -416.3565448097753 - buffer size 17015 - timestep  89\n",
      "Episode  112 - score  -953.050673329678 - average score  -425.0344039114625 - buffer size 17113 - timestep  98\n",
      "Episode  113 - score  -788.017820869003 - average score  -432.1903155763233 - buffer size 17203 - timestep  90\n",
      "Episode  114 - score  -915.9096143481472 - average score  -436.68888546279857 - buffer size 17433 - timestep  230\n",
      "Episode  115 - score  -368.68997530601814 - average score  -437.8562642272011 - buffer size 17572 - timestep  139\n",
      "Episode  116 - score  -609.8209098562351 - average score  -443.46349350987083 - buffer size 17699 - timestep  127\n",
      "Episode  117 - score  -221.4809388126109 - average score  -441.91214744242484 - buffer size 17801 - timestep  102\n",
      "Episode  118 - score  -592.2748103127349 - average score  -447.2123798803462 - buffer size 18000 - timestep  199\n",
      "Episode  119 - score  -558.860516561343 - average score  -448.815141587951 - buffer size 18104 - timestep  104\n",
      "Episode  120 - score  -806.6180519225795 - average score  -453.5863883919277 - buffer size 18263 - timestep  159\n",
      "Episode  121 - score  -389.97981674412637 - average score  -454.7586579217865 - buffer size 18361 - timestep  98\n",
      "Episode  122 - score  -392.05819947474265 - average score  -455.65922515589233 - buffer size 18458 - timestep  97\n",
      "Episode  123 - score  -870.5453098833018 - average score  -461.69177746096955 - buffer size 18611 - timestep  153\n",
      "Episode  124 - score  -776.3581866729851 - average score  -468.10212784553283 - buffer size 18701 - timestep  90\n",
      "Episode  125 - score  -729.4432485201401 - average score  -472.73162071063035 - buffer size 18793 - timestep  92\n",
      "Episode  126 - score  -422.12967501960856 - average score  -474.4956301578802 - buffer size 18891 - timestep  98\n",
      "Episode  127 - score  -335.03560250001726 - average score  -474.99938334174544 - buffer size 19011 - timestep  120\n",
      "Episode  128 - score  -829.7197154645291 - average score  -480.2738047788409 - buffer size 19167 - timestep  156\n",
      "Episode  129 - score  -488.78204698347395 - average score  -482.3876156854047 - buffer size 19261 - timestep  94\n",
      "Episode  130 - score  -380.5222730987923 - average score  -482.1618632644329 - buffer size 19517 - timestep  256\n",
      "Episode  131 - score  -602.479663812149 - average score  -485.00463215000696 - buffer size 19712 - timestep  195\n",
      "Episode  132 - score  -546.3889473310613 - average score  -486.1459529501517 - buffer size 19864 - timestep  152\n",
      "Episode  133 - score  -359.60198108738444 - average score  -489.36650289151544 - buffer size 19993 - timestep  129\n",
      "Episode  134 - score  -637.2058938883667 - average score  -492.7169898649274 - buffer size 20135 - timestep  142\n",
      "Episode  135 - score  -516.5538636319121 - average score  -495.19508884185814 - buffer size 20221 - timestep  86\n",
      "Episode  136 - score  -576.1356431035363 - average score  -496.1657914676144 - buffer size 20356 - timestep  135\n",
      "Episode  137 - score  -198.0914538995334 - average score  -494.17684368475216 - buffer size 20458 - timestep  102\n",
      "Episode  138 - score  -483.79373459939217 - average score  -495.80239879793686 - buffer size 20549 - timestep  91\n",
      "Episode  139 - score  -378.5501392492598 - average score  -498.7189301669818 - buffer size 20676 - timestep  127\n",
      "Episode  140 - score  -458.98119987607356 - average score  -501.4726432275311 - buffer size 20938 - timestep  262\n",
      "Episode  141 - score  -473.1491722478607 - average score  -505.5417155897404 - buffer size 21073 - timestep  135\n",
      "Episode  142 - score  -1028.4067266445268 - average score  -512.5341641304004 - buffer size 21646 - timestep  573\n",
      "Episode  143 - score  -66.39704000546406 - average score  -510.2930080436161 - buffer size 21758 - timestep  112\n",
      "Episode  144 - score  -645.9234930247665 - average score  -512.9497619809604 - buffer size 22093 - timestep  335\n",
      "Episode  145 - score  -530.9769022599728 - average score  -516.0568442659492 - buffer size 22237 - timestep  144\n",
      "Episode  146 - score  -522.5463391264655 - average score  -518.2304515692954 - buffer size 22375 - timestep  138\n",
      "Episode  147 - score  -388.07605959771865 - average score  -518.5281898129937 - buffer size 22508 - timestep  133\n",
      "Episode  148 - score  -383.54319136887693 - average score  -521.2511427239823 - buffer size 22646 - timestep  138\n",
      "Episode  149 - score  -451.50778855373164 - average score  -523.0381452530955 - buffer size 22800 - timestep  154\n",
      "Episode  150 - score  -379.7367682967703 - average score  -526.983257124703 - buffer size 22944 - timestep  144\n",
      "Episode  151 - score  -541.7724525034778 - average score  -527.7900100793717 - buffer size 23078 - timestep  134\n",
      "Episode  152 - score  -491.4266433176764 - average score  -530.1304268375117 - buffer size 23242 - timestep  164\n",
      "Episode  153 - score  -213.42857050056773 - average score  -528.9718886306456 - buffer size 23360 - timestep  118\n",
      "Episode  154 - score  -403.2669919227541 - average score  -528.9163921650689 - buffer size 23447 - timestep  87\n",
      "Episode  155 - score  -483.71492979422317 - average score  -530.4994195484865 - buffer size 23629 - timestep  182\n",
      "Episode  156 - score  -402.50548248757485 - average score  -530.1624483559285 - buffer size 23800 - timestep  171\n",
      "Episode  157 - score  -460.08147119288617 - average score  -534.5765473598781 - buffer size 23946 - timestep  146\n",
      "Episode  158 - score  -391.290387555365 - average score  -534.2849314078826 - buffer size 24103 - timestep  157\n",
      "Episode  159 - score  -526.8753484220277 - average score  -536.5810123276965 - buffer size 24251 - timestep  148\n",
      "Episode  160 - score  -250.68620253808692 - average score  -535.258220494309 - buffer size 24359 - timestep  108\n",
      "Episode  161 - score  -361.3510592565256 - average score  -536.2820571090934 - buffer size 24522 - timestep  163\n",
      "Episode  162 - score  -67.33053139112867 - average score  -536.4502197851916 - buffer size 24657 - timestep  135\n",
      "Episode  163 - score  -352.11511531057215 - average score  -537.6392116731741 - buffer size 24798 - timestep  141\n",
      "Episode  164 - score  -215.31297088419538 - average score  -540.0039990908482 - buffer size 24993 - timestep  195\n",
      "Episode  165 - score  -398.15927347382615 - average score  -539.5542460253264 - buffer size 25134 - timestep  141\n",
      "Episode  166 - score  -718.8151449230766 - average score  -540.9237372257847 - buffer size 25279 - timestep  145\n",
      "Episode  167 - score  -847.1311415456593 - average score  -545.4778729067486 - buffer size 25433 - timestep  154\n",
      "Episode  168 - score  -308.5997085781969 - average score  -542.418859645653 - buffer size 25575 - timestep  142\n",
      "Episode  169 - score  -264.8521893111591 - average score  -539.1759938979754 - buffer size 25767 - timestep  192\n",
      "Episode  170 - score  -162.44259731726993 - average score  -536.7733427975779 - buffer size 25989 - timestep  222\n",
      "Episode  171 - score  -161.76021462983482 - average score  -536.2689771792016 - buffer size 26213 - timestep  224\n",
      "Episode  172 - score  -203.78285120331532 - average score  -534.4070418156837 - buffer size 26320 - timestep  107\n",
      "Episode  173 - score  -482.71102338167134 - average score  -533.1231739631462 - buffer size 26470 - timestep  150\n",
      "Episode  174 - score  -671.7013533707666 - average score  -534.5936526710544 - buffer size 26616 - timestep  146\n",
      "Episode  175 - score  -506.4656324090026 - average score  -536.0327384093599 - buffer size 26768 - timestep  152\n",
      "Episode  176 - score  -635.7651886125147 - average score  -538.8049654310007 - buffer size 26908 - timestep  140\n",
      "Episode  177 - score  -329.78798373899525 - average score  -539.6364652745768 - buffer size 27125 - timestep  217\n",
      "Episode  178 - score  39.18488465492041 - average score  -537.1759787544655 - buffer size 27424 - timestep  299\n",
      "Episode  179 - score  -418.1772789203286 - average score  -531.3530623971299 - buffer size 27664 - timestep  240\n",
      "Episode  180 - score  -449.8254746040834 - average score  -533.0808923808573 - buffer size 27811 - timestep  147\n",
      "Episode  181 - score  -253.47910096996773 - average score  -533.8552830260619 - buffer size 27983 - timestep  172\n",
      "Episode  182 - score  -76.27509036848447 - average score  -530.6357947436426 - buffer size 28155 - timestep  172\n",
      "Episode  183 - score  -338.54836984944416 - average score  -530.056096046748 - buffer size 28298 - timestep  143\n",
      "Episode  184 - score  -416.5759192212374 - average score  -530.3518917100797 - buffer size 28456 - timestep  158\n",
      "Episode  185 - score  -344.22826114561235 - average score  -531.4902518778097 - buffer size 28705 - timestep  249\n",
      "Episode  186 - score  -362.24391092535006 - average score  -531.1887210384863 - buffer size 28872 - timestep  167\n",
      "Episode  187 - score  -311.15646469086676 - average score  -527.9616151175094 - buffer size 29196 - timestep  324\n",
      "Episode  188 - score  -544.3130200245935 - average score  -530.1565054265665 - buffer size 29388 - timestep  192\n",
      "Episode  189 - score  -333.92364816278723 - average score  -527.8357567700754 - buffer size 29588 - timestep  200\n",
      "Episode  190 - score  -381.28902745782796 - average score  -528.6076497443747 - buffer size 29865 - timestep  277\n",
      "Episode  191 - score  -183.80336296648187 - average score  -524.1813427168432 - buffer size 30074 - timestep  209\n",
      "Episode  192 - score  -81.59968244266958 - average score  -520.7037117108732 - buffer size 30280 - timestep  206\n",
      "Episode  193 - score  -294.76546383545593 - average score  -515.9470681851931 - buffer size 30552 - timestep  272\n",
      "Episode  194 - score  -299.10553623090664 - average score  -513.372446219927 - buffer size 30698 - timestep  146\n",
      "Episode  195 - score  -241.5070428427963 - average score  -508.8199594899041 - buffer size 30857 - timestep  159\n",
      "Episode  196 - score  -330.9776123469429 - average score  -507.87368939254134 - buffer size 31040 - timestep  183\n",
      "Episode  197 - score  218.7003512696384 - average score  -499.9224694143539 - buffer size 31340 - timestep  300\n",
      "Episode  198 - score  -149.04917904176878 - average score  -492.4589216841294 - buffer size 31509 - timestep  169\n",
      "Episode  199 - score  -72.69356464350838 - average score  -484.2401826647606 - buffer size 31660 - timestep  151\n",
      "Episode  200 - score  -131.36238260696913 - average score  -478.26983323679974 - buffer size 31945 - timestep  285\n",
      "Episode  201 - score  -635.0698134137755 - average score  -477.8342783798601 - buffer size 32184 - timestep  239\n",
      "Episode  202 - score  -718.8494537253647 - average score  -473.5442026833337 - buffer size 32411 - timestep  227\n",
      "Episode  203 - score  -113.45034812176351 - average score  -464.692501409235 - buffer size 32669 - timestep  258\n",
      "Episode  204 - score  -556.3414488391733 - average score  -461.50398504276495 - buffer size 32981 - timestep  312\n",
      "Episode  205 - score  -268.30426263707056 - average score  -453.51409546826585 - buffer size 33263 - timestep  282\n",
      "Episode  206 - score  -105.67816159417599 - average score  -446.41101383085703 - buffer size 33461 - timestep  198\n",
      "Episode  207 - score  -233.98101368564264 - average score  -439.01744654844856 - buffer size 33841 - timestep  380\n",
      "Episode  208 - score  -124.24265927688394 - average score  -430.3338056922335 - buffer size 34071 - timestep  230\n",
      "Episode  209 - score  -147.49215342878747 - average score  -421.3122119426196 - buffer size 34471 - timestep  400\n",
      "Episode  210 - score  -136.5329833803433 - average score  -415.7788264440571 - buffer size 35039 - timestep  568\n",
      "Episode  211 - score  -88.48179924296963 - average score  -407.9591410157671 - buffer size 35271 - timestep  232\n",
      "Episode  212 - score  -210.69202821056837 - average score  -400.5355545645761 - buffer size 35619 - timestep  348\n",
      "Episode  213 - score  -318.5605663942089 - average score  -395.84098201982806 - buffer size 35794 - timestep  175\n",
      "Episode  214 - score  -415.2904327490273 - average score  -390.834790203837 - buffer size 36435 - timestep  641\n",
      "Episode  215 - score  -192.55984928333714 - average score  -389.07348894361013 - buffer size 36666 - timestep  231\n",
      "Episode  216 - score  -205.58134676505432 - average score  -385.03109331269826 - buffer size 36911 - timestep  245\n",
      "Episode  217 - score  -301.44089917425515 - average score  -385.83069291631466 - buffer size 37324 - timestep  413\n",
      "Episode  218 - score  -469.6079040416656 - average score  -384.604023853604 - buffer size 37544 - timestep  220\n",
      "Episode  219 - score  -218.87289316789185 - average score  -381.20414761966947 - buffer size 37804 - timestep  260\n",
      "Episode  220 - score  -267.9372351415643 - average score  -375.81733945185937 - buffer size 38106 - timestep  302\n",
      "Episode  221 - score  -121.85159901786294 - average score  -373.13605727459674 - buffer size 38328 - timestep  222\n",
      "Episode  222 - score  -303.4966420636406 - average score  -372.25044170048574 - buffer size 38573 - timestep  245\n",
      "Episode  223 - score  -256.09934573517546 - average score  -366.1059820590045 - buffer size 38829 - timestep  256\n",
      "Episode  224 - score  -238.83261559806698 - average score  -360.73072634825525 - buffer size 38993 - timestep  164\n",
      "Episode  225 - score  -369.7162891551535 - average score  -357.13345675460545 - buffer size 39251 - timestep  258\n",
      "Episode  226 - score  -301.4722813523809 - average score  -355.9268828179331 - buffer size 39515 - timestep  264\n",
      "Episode  227 - score  -471.1948743749717 - average score  -357.2884755366828 - buffer size 39746 - timestep  231\n",
      "Episode  228 - score  -260.41167779039705 - average score  -351.59539515994146 - buffer size 39927 - timestep  181\n",
      "Episode  229 - score  -110.09604251360865 - average score  -347.8085351152427 - buffer size 40135 - timestep  208\n",
      "Episode  230 - score  -421.544173384236 - average score  -348.2187541180972 - buffer size 40383 - timestep  248\n",
      "Episode  231 - score  -287.25464883150835 - average score  -345.0665039682907 - buffer size 40641 - timestep  258\n",
      "Episode  232 - score  -498.32759735981796 - average score  -344.58589046857827 - buffer size 40846 - timestep  205\n",
      "Episode  233 - score  -421.23855744070926 - average score  -345.20225623211155 - buffer size 41085 - timestep  239\n",
      "Episode  234 - score  -759.8814183811392 - average score  -346.4290114770393 - buffer size 41430 - timestep  345\n",
      "Episode  235 - score  -500.6131777419155 - average score  -346.26960461813934 - buffer size 41748 - timestep  318\n",
      "Episode  236 - score  -374.11367600340867 - average score  -344.249384947138 - buffer size 41924 - timestep  176\n",
      "Episode  237 - score  -275.0712206503375 - average score  -345.01918261464607 - buffer size 42250 - timestep  326\n",
      "Episode  238 - score  -353.3290274604482 - average score  -343.71453554325666 - buffer size 42590 - timestep  340\n",
      "Episode  239 - score  -346.07863232158417 - average score  -343.3898204739799 - buffer size 42904 - timestep  314\n",
      "Episode  240 - score  -34.578992954182524 - average score  -339.1457984047611 - buffer size 43095 - timestep  191\n",
      "Episode  241 - score  -197.74034677206913 - average score  -336.3917101500032 - buffer size 43296 - timestep  201\n",
      "Episode  242 - score  -203.4583490918538 - average score  -328.1422263744763 - buffer size 43589 - timestep  293\n",
      "Episode  243 - score  -274.054508382608 - average score  -330.2188010582477 - buffer size 43795 - timestep  206\n",
      "Episode  244 - score  -411.0537245417275 - average score  -327.8701033734173 - buffer size 44022 - timestep  227\n",
      "Episode  245 - score  -306.7981366269921 - average score  -325.62831571708756 - buffer size 44220 - timestep  198\n",
      "Episode  246 - score  -452.9255144570452 - average score  -324.93210747039336 - buffer size 44380 - timestep  160\n",
      "Episode  247 - score  -434.00664173576655 - average score  -325.39141329177386 - buffer size 44671 - timestep  291\n",
      "Episode  248 - score  -499.1366653958728 - average score  -326.5473480320438 - buffer size 44871 - timestep  200\n",
      "Episode  249 - score  -355.0534547494642 - average score  -325.58280469400114 - buffer size 45152 - timestep  281\n",
      "Episode  250 - score  -302.9482956194603 - average score  -324.81491996722804 - buffer size 45416 - timestep  264\n",
      "Episode  251 - score  -431.3853359435956 - average score  -323.7110488016292 - buffer size 45609 - timestep  193\n",
      "Episode  252 - score  -87.73137558059442 - average score  -319.67409612425837 - buffer size 45805 - timestep  196\n",
      "Episode  253 - score  -698.1830603156164 - average score  -324.52164102240886 - buffer size 46063 - timestep  258\n",
      "Episode  254 - score  -377.17429256823056 - average score  -324.2607140288636 - buffer size 46273 - timestep  210\n",
      "Episode  255 - score  -168.8474752812619 - average score  -321.112039483734 - buffer size 46513 - timestep  240\n",
      "Episode  256 - score  -185.3392482222813 - average score  -318.94037714108106 - buffer size 46834 - timestep  321\n",
      "Episode  257 - score  -111.92029601157913 - average score  -315.458765389268 - buffer size 46987 - timestep  153\n",
      "Episode  258 - score  -253.87455780289199 - average score  -314.0846070917433 - buffer size 47151 - timestep  164\n",
      "Episode  259 - score  -84.97301568279055 - average score  -309.6655837643509 - buffer size 47358 - timestep  207\n",
      "Episode  260 - score  -383.32529390491356 - average score  -310.9919746780191 - buffer size 47594 - timestep  236\n",
      "Episode  261 - score  -224.5162902567845 - average score  -309.6236269880217 - buffer size 47779 - timestep  185\n",
      "Episode  262 - score  -227.12101321462825 - average score  -311.22153180625673 - buffer size 48160 - timestep  381\n",
      "Episode  263 - score  -126.58831339556734 - average score  -308.9662637871067 - buffer size 48500 - timestep  340\n",
      "Episode  264 - score  -358.7881564346943 - average score  -310.4010156426117 - buffer size 48734 - timestep  234\n",
      "Episode  265 - score  -580.9627519763235 - average score  -312.2290504276367 - buffer size 49467 - timestep  733\n",
      "Episode  266 - score  -370.38051240660127 - average score  -308.7447041024719 - buffer size 49606 - timestep  139\n",
      "Episode  267 - score  -295.58012887902396 - average score  -303.2291939758055 - buffer size 49786 - timestep  180\n",
      "Episode  268 - score  -844.3754021301459 - average score  -308.58695091132506 - buffer size 50113 - timestep  327\n",
      "Episode  269 - score  -447.0997637014592 - average score  -310.40942665522806 - buffer size 50318 - timestep  205\n",
      "Episode  270 - score  -294.35351478466754 - average score  -311.72853582990206 - buffer size 50539 - timestep  221\n",
      "Episode  271 - score  -435.447570084311 - average score  -314.46540938444673 - buffer size 50767 - timestep  228\n",
      "Episode  272 - score  -658.0138689732075 - average score  -319.0077195621457 - buffer size 51011 - timestep  244\n",
      "Episode  273 - score  -291.27339882706093 - average score  -317.0933433165996 - buffer size 51269 - timestep  258\n",
      "Episode  274 - score  -253.57156620754807 - average score  -312.9120454449674 - buffer size 51600 - timestep  331\n",
      "Episode  275 - score  -758.7241669979331 - average score  -315.4346307908567 - buffer size 51814 - timestep  214\n",
      "Episode  276 - score  -80.09747870333976 - average score  -309.877953691765 - buffer size 52010 - timestep  196\n",
      "Episode  277 - score  -279.75242923483825 - average score  -309.37759814672347 - buffer size 52305 - timestep  295\n",
      "Episode  278 - score  -238.70422248736685 - average score  -312.1564892181463 - buffer size 52580 - timestep  275\n",
      "Episode  279 - score  -466.6413200421874 - average score  -312.64112962936485 - buffer size 52874 - timestep  294\n",
      "Episode  280 - score  -513.6836335616106 - average score  -313.2797112189402 - buffer size 53001 - timestep  127\n",
      "Episode  281 - score  -219.8882905049706 - average score  -312.9438031142902 - buffer size 53218 - timestep  217\n",
      "Episode  282 - score  -363.5967646326961 - average score  -315.81701985693235 - buffer size 53357 - timestep  139\n",
      "Episode  283 - score  -144.94387906504397 - average score  -313.8809749490884 - buffer size 53625 - timestep  268\n",
      "Episode  284 - score  -744.8003846359062 - average score  -317.16321960323506 - buffer size 53916 - timestep  291\n",
      "Episode  285 - score  -495.9888991767515 - average score  -318.6808259835464 - buffer size 54210 - timestep  294\n",
      "Episode  286 - score  -381.7013086344387 - average score  -318.8753999606373 - buffer size 54465 - timestep  255\n",
      "Episode  287 - score  -229.9591079298005 - average score  -318.0634263930266 - buffer size 54671 - timestep  206\n",
      "Episode  288 - score  -483.3568198937596 - average score  -317.4538643917183 - buffer size 54924 - timestep  253\n",
      "Episode  289 - score  -318.54524343472633 - average score  -317.3000803444377 - buffer size 55187 - timestep  263\n",
      "Episode  290 - score  -540.0503615709226 - average score  -318.88769368556865 - buffer size 55425 - timestep  238\n",
      "Episode  291 - score  -282.68121114111216 - average score  -319.87647216731494 - buffer size 55684 - timestep  259\n",
      "Episode  292 - score  -645.1804400584798 - average score  -325.5122797434731 - buffer size 55930 - timestep  246\n",
      "Episode  293 - score  -276.25987245912006 - average score  -325.3272238297097 - buffer size 56191 - timestep  261\n",
      "Episode  294 - score  -368.1909943957813 - average score  -326.0180784113583 - buffer size 56588 - timestep  397\n",
      "Episode  295 - score  -623.1981763535966 - average score  -329.83498974646636 - buffer size 57363 - timestep  775\n",
      "Episode  296 - score  -102.3724091602412 - average score  -327.54893771459933 - buffer size 57567 - timestep  204\n",
      "Episode  297 - score  -749.4186731084667 - average score  -337.2301279583805 - buffer size 57858 - timestep  291\n",
      "Episode  298 - score  -148.89954647493715 - average score  -337.2286316327121 - buffer size 58387 - timestep  529\n",
      "Episode  299 - score  -725.4755510748017 - average score  -343.75645149702507 - buffer size 58793 - timestep  406\n",
      "Episode  300 - score  -444.33495722768924 - average score  -346.8861772432322 - buffer size 59156 - timestep  363\n",
      "Episode  301 - score  -151.04284584490773 - average score  -342.04590756754357 - buffer size 59307 - timestep  151\n",
      "Episode  302 - score  -205.65415439185628 - average score  -336.91395457420845 - buffer size 59484 - timestep  177\n",
      "Episode  303 - score  -774.8404961628296 - average score  -343.5278560546192 - buffer size 59694 - timestep  210\n",
      "Episode  304 - score  -291.7957809146538 - average score  -340.882399375374 - buffer size 59998 - timestep  304\n",
      "Episode  305 - score  -562.0139310836919 - average score  -343.81949605984016 - buffer size 60204 - timestep  206\n",
      "Episode  306 - score  -249.53722275559014 - average score  -345.2580866714543 - buffer size 60381 - timestep  177\n",
      "Episode  307 - score  -458.1503548561397 - average score  -347.4997800831593 - buffer size 60558 - timestep  177\n",
      "Episode  308 - score  -99.05074471505635 - average score  -347.247860937541 - buffer size 60802 - timestep  244\n",
      "Episode  309 - score  -104.64810356071789 - average score  -346.8194204388604 - buffer size 60967 - timestep  165\n",
      "Episode  310 - score  -288.01575422549905 - average score  -348.3342481473119 - buffer size 61498 - timestep  531\n",
      "Episode  311 - score  -397.8063174501184 - average score  -351.4274933293833 - buffer size 61776 - timestep  278\n",
      "Episode  312 - score  -365.88194783506253 - average score  -352.97939252562827 - buffer size 61992 - timestep  216\n",
      "Episode  313 - score  -520.3835338998151 - average score  -354.99762220068436 - buffer size 62251 - timestep  259\n",
      "Episode  314 - score  -319.5036293604859 - average score  -354.03975416679896 - buffer size 62370 - timestep  119\n",
      "Episode  315 - score  -97.54887635419387 - average score  -353.0896444375075 - buffer size 62724 - timestep  354\n",
      "Episode  316 - score  -273.6994608297473 - average score  -353.7708255781545 - buffer size 62974 - timestep  250\n",
      "Episode  317 - score  -322.3392475173227 - average score  -353.9798090615851 - buffer size 63099 - timestep  125\n",
      "Episode  318 - score  -185.96951205265424 - average score  -351.143425141695 - buffer size 63738 - timestep  639\n",
      "Episode  319 - score  -160.5251471399054 - average score  -350.55994768141505 - buffer size 64187 - timestep  449\n",
      "Episode  320 - score  -604.3695735643835 - average score  -353.92427106564327 - buffer size 64587 - timestep  400\n",
      "Episode  321 - score  -408.02001507981305 - average score  -356.78595522626273 - buffer size 64901 - timestep  314\n",
      "Episode  322 - score  -371.22959815305256 - average score  -357.46328478715697 - buffer size 65144 - timestep  243\n",
      "Episode  323 - score  -482.35646069761543 - average score  -359.7258559367813 - buffer size 65341 - timestep  197\n",
      "Episode  324 - score  -380.41395984828074 - average score  -361.1416693792835 - buffer size 65493 - timestep  152\n",
      "Episode  325 - score  -589.1727874328305 - average score  -363.3362343620602 - buffer size 65749 - timestep  256\n",
      "Episode  326 - score  -398.70545737229696 - average score  -364.3085661222594 - buffer size 66075 - timestep  326\n",
      "Episode  327 - score  -180.1447379938627 - average score  -361.3980647584483 - buffer size 66431 - timestep  356\n",
      "Episode  328 - score  -122.14733162882114 - average score  -360.01542129683264 - buffer size 66787 - timestep  356\n",
      "Episode  329 - score  -497.328897212351 - average score  -363.88774984381996 - buffer size 67175 - timestep  388\n",
      "Episode  330 - score  -360.2012351656576 - average score  -363.2743204616342 - buffer size 67384 - timestep  209\n",
      "Episode  331 - score  -266.22595416756525 - average score  -363.06403351499483 - buffer size 67685 - timestep  301\n",
      "Episode  332 - score  -399.4794141618113 - average score  -362.07555168301474 - buffer size 67811 - timestep  126\n",
      "Episode  333 - score  -271.69055296113754 - average score  -360.580071638219 - buffer size 67951 - timestep  140\n",
      "Episode  334 - score  -290.69501528777965 - average score  -355.8882076072854 - buffer size 68706 - timestep  755\n",
      "Episode  335 - score  -194.21892247189842 - average score  -352.82426505458517 - buffer size 68918 - timestep  212\n",
      "Episode  336 - score  -240.56105683768828 - average score  -351.4887388629279 - buffer size 69108 - timestep  190\n",
      "Episode  337 - score  -207.84154298585244 - average score  -350.81644208628313 - buffer size 69471 - timestep  363\n",
      "Episode  338 - score  -219.59600539706474 - average score  -349.4791118656493 - buffer size 69744 - timestep  273\n",
      "Episode  339 - score  -496.6341592868305 - average score  -350.98466713530183 - buffer size 70077 - timestep  333\n",
      "Episode  340 - score  -255.2762515181848 - average score  -353.19163972094174 - buffer size 70407 - timestep  330\n",
      "Episode  341 - score  -375.6200681446942 - average score  -354.97043693466804 - buffer size 71361 - timestep  954\n",
      "Episode  342 - score  -333.25207386549016 - average score  -356.2683741824045 - buffer size 71885 - timestep  524\n",
      "Episode  343 - score  -651.2915130634584 - average score  -360.0407442292129 - buffer size 72315 - timestep  430\n",
      "Episode  344 - score  -532.6172125031408 - average score  -361.2563791088271 - buffer size 72700 - timestep  385\n",
      "Episode  345 - score  -325.2347973863135 - average score  -361.4407457164203 - buffer size 72966 - timestep  266\n",
      "Episode  346 - score  202.49680950824575 - average score  -354.88652247676737 - buffer size 73525 - timestep  559\n",
      "Episode  347 - score  -287.80124769658687 - average score  -353.4244685363756 - buffer size 73955 - timestep  430\n",
      "Episode  348 - score  -143.95554039500615 - average score  -349.872657286367 - buffer size 74373 - timestep  418\n",
      "Episode  349 - score  -87.24007185091125 - average score  -347.1945234573814 - buffer size 74674 - timestep  301\n",
      "Episode  350 - score  -403.4909221198129 - average score  -348.19994972238493 - buffer size 75031 - timestep  357\n",
      "Episode  351 - score  -186.59852822091352 - average score  -345.7520816451581 - buffer size 75306 - timestep  275\n",
      "Episode  352 - score  -417.4743338808501 - average score  -349.04951122816055 - buffer size 75583 - timestep  277\n",
      "Episode  353 - score  -258.00656649452304 - average score  -344.64774628994974 - buffer size 76014 - timestep  431\n",
      "Episode  354 - score  -317.3286383250911 - average score  -344.0492897475183 - buffer size 76679 - timestep  665\n",
      "Episode  355 - score  -349.13229659404936 - average score  -345.85213796064613 - buffer size 76790 - timestep  111\n",
      "Episode  356 - score  -271.42907139096883 - average score  -346.7130361923331 - buffer size 76994 - timestep  204\n",
      "Episode  357 - score  -231.28830995596496 - average score  -347.9067163317769 - buffer size 77428 - timestep  434\n",
      "Episode  358 - score  -67.41279889835963 - average score  -346.04209874273164 - buffer size 77622 - timestep  194\n",
      "Episode  359 - score  -253.70647199797278 - average score  -347.7294333058835 - buffer size 77850 - timestep  228\n",
      "Episode  360 - score  -233.17902548018589 - average score  -346.22797062163625 - buffer size 78172 - timestep  322\n",
      "Episode  361 - score  -198.4754536042925 - average score  -345.96756225511126 - buffer size 78382 - timestep  210\n",
      "Episode  362 - score  149.19051122445148 - average score  -342.2044470107205 - buffer size 79366 - timestep  984\n",
      "Episode  363 - score  -162.23848416246435 - average score  -342.5609487183894 - buffer size 79755 - timestep  389\n",
      "Episode  364 - score  -273.94883179726264 - average score  -341.71255547201514 - buffer size 80253 - timestep  498\n",
      "Episode  365 - score  -127.579684161568 - average score  -337.17872479386756 - buffer size 80710 - timestep  457\n",
      "Episode  366 - score  -302.1662942864565 - average score  -336.4965826126661 - buffer size 80930 - timestep  220\n",
      "Episode  367 - score  -153.03452130315412 - average score  -335.0711265369074 - buffer size 81088 - timestep  158\n",
      "Episode  368 - score  -499.1489861174837 - average score  -331.6188623767807 - buffer size 81404 - timestep  316\n",
      "Episode  369 - score  -541.7072107183579 - average score  -332.56493684694976 - buffer size 81688 - timestep  284\n",
      "Episode  370 - score  -199.02970688483077 - average score  -331.6116987679514 - buffer size 82068 - timestep  380\n",
      "Episode  371 - score  -382.4310366080276 - average score  -331.0815334331886 - buffer size 82538 - timestep  470\n",
      "Episode  372 - score  -370.84284322736244 - average score  -328.20982317573015 - buffer size 82888 - timestep  350\n",
      "Episode  373 - score  -284.2154325685502 - average score  -328.13924351314495 - buffer size 83154 - timestep  266\n",
      "Episode  374 - score  -317.1187451578172 - average score  -328.7747153026477 - buffer size 83521 - timestep  367\n",
      "Episode  375 - score  -284.11631323653296 - average score  -324.0286367650337 - buffer size 83867 - timestep  346\n",
      "Episode  376 - score  -246.60230978200872 - average score  -325.6936850758204 - buffer size 83994 - timestep  127\n",
      "Episode  377 - score  -442.3012067111647 - average score  -327.3191728505836 - buffer size 84455 - timestep  461\n",
      "Episode  378 - score  -10.809013878926592 - average score  -325.0402207644992 - buffer size 84657 - timestep  202\n",
      "Episode  379 - score  -226.37045982546624 - average score  -322.637512162332 - buffer size 84911 - timestep  254\n",
      "Episode  380 - score  -277.66752339485265 - average score  -320.27735106066444 - buffer size 85220 - timestep  309\n",
      "Episode  381 - score  -387.30867323729086 - average score  -321.95155488798764 - buffer size 85351 - timestep  131\n",
      "Episode  382 - score  -207.37154683896608 - average score  -320.38930271005034 - buffer size 85690 - timestep  339\n",
      "Episode  383 - score  -346.7074768446326 - average score  -322.4069386878462 - buffer size 86170 - timestep  480\n",
      "Episode  384 - score  -361.3037715212079 - average score  -318.5719725566993 - buffer size 87073 - timestep  903\n",
      "Episode  385 - score  -527.4162139576297 - average score  -318.88624570450804 - buffer size 87952 - timestep  879\n",
      "Episode  386 - score  -87.16641855159308 - average score  -315.94089680367955 - buffer size 88409 - timestep  457\n",
      "Episode  387 - score  -333.56246063301865 - average score  -316.9769303307118 - buffer size 88722 - timestep  313\n",
      "Episode  388 - score  -250.34787254749094 - average score  -314.6468408572491 - buffer size 88934 - timestep  212\n",
      "Episode  389 - score  -634.3070875081316 - average score  -317.80445929798316 - buffer size 90381 - timestep  1447\n",
      "Episode  390 - score  -282.5949786421654 - average score  -315.22990546869556 - buffer size 91204 - timestep  823\n",
      "Episode  391 - score  -260.9176596937307 - average score  -315.01226995422184 - buffer size 91579 - timestep  375\n",
      "Episode  392 - score  -391.73823061518914 - average score  -312.4778478597889 - buffer size 92623 - timestep  1044\n",
      "Episode  393 - score  -555.719785568336 - average score  -315.272446990881 - buffer size 93039 - timestep  416\n",
      "Episode  394 - score  -456.94659349930635 - average score  -316.16000298191625 - buffer size 94141 - timestep  1102\n",
      "Episode  395 - score  -275.91635344656277 - average score  -312.68718475284595 - buffer size 94503 - timestep  362\n",
      "Episode  396 - score  -504.2543112612493 - average score  -316.70600377385597 - buffer size 94767 - timestep  264\n",
      "Episode  397 - score  -595.8544354789324 - average score  -315.1703613975607 - buffer size 95845 - timestep  1078\n",
      "Episode  398 - score  -437.0836005805107 - average score  -318.05220193861635 - buffer size 96550 - timestep  705\n",
      "Episode  399 - score  -172.06167946536465 - average score  -312.518063222522 - buffer size 97113 - timestep  563\n",
      "Episode  400 - score  -414.34959419765045 - average score  -312.2182095922216 - buffer size 97445 - timestep  332\n",
      "Episode  401 - score  -251.64996018409303 - average score  -313.2242807356135 - buffer size 97632 - timestep  187\n",
      "Episode  402 - score  -470.00493863346566 - average score  -315.86778857802955 - buffer size 98728 - timestep  1096\n",
      "Episode  403 - score  -565.2072493579333 - average score  -313.7714561099806 - buffer size 99561 - timestep  833\n",
      "Episode  404 - score  -415.76856672380256 - average score  -315.0111839680721 - buffer size 101125 - timestep  1564\n",
      "Episode  405 - score  -480.952629915935 - average score  -314.20057095639453 - buffer size 102684 - timestep  1559\n",
      "Episode  406 - score  -60.67404814001075 - average score  -312.31193921023873 - buffer size 103155 - timestep  471\n",
      "Episode  407 - score  -399.6370058260354 - average score  -311.7268057199377 - buffer size 103898 - timestep  743\n",
      "Episode  408 - score  -414.4776886427145 - average score  -314.8810751592142 - buffer size 105033 - timestep  1135\n",
      "Episode  409 - score  -476.87139949117244 - average score  -318.60330811851884 - buffer size 105817 - timestep  784\n",
      "Episode  410 - score  -304.0260525074411 - average score  -318.76341110133825 - buffer size 106331 - timestep  514\n",
      "Episode  411 - score  -378.73786761485985 - average score  -318.57272660298565 - buffer size 106860 - timestep  529\n",
      "Episode  412 - score  -262.45056533481556 - average score  -317.5384127779832 - buffer size 107262 - timestep  402\n",
      "Episode  413 - score  -444.46976259144213 - average score  -316.7792750648994 - buffer size 108126 - timestep  864\n",
      "Episode  414 - score  -243.9893807929977 - average score  -316.02413257922456 - buffer size 108719 - timestep  593\n",
      "Episode  415 - score  -254.43666579539962 - average score  -317.5930104736366 - buffer size 109075 - timestep  356\n",
      "Episode  416 - score  -314.26663521222804 - average score  -317.9986822174614 - buffer size 109558 - timestep  483\n",
      "Episode  417 - score  -375.2350911800452 - average score  -318.5276406540886 - buffer size 109835 - timestep  277\n",
      "Episode  418 - score  -663.2539494808004 - average score  -323.3004850283701 - buffer size 111013 - timestep  1178\n",
      "Episode  419 - score  -292.8497168370741 - average score  -324.6237307253418 - buffer size 111394 - timestep  381\n",
      "Episode  420 - score  -261.8751211260958 - average score  -321.1987862009589 - buffer size 111777 - timestep  383\n",
      "Episode  421 - score  -251.31614261869535 - average score  -319.63174747634775 - buffer size 112358 - timestep  581\n",
      "Episode  422 - score  -155.92642592350637 - average score  -317.4787157540523 - buffer size 112975 - timestep  617\n",
      "Episode  423 - score  -506.9548233809066 - average score  -317.7246993808852 - buffer size 114600 - timestep  1625\n",
      "Episode  424 - score  -334.83007970306335 - average score  -317.268860579433 - buffer size 115442 - timestep  842\n",
      "Episode  425 - score  -130.46642193299488 - average score  -312.68179692443465 - buffer size 115918 - timestep  476\n",
      "Episode  426 - score  -139.3905257473511 - average score  -310.0886476081852 - buffer size 116369 - timestep  451\n",
      "Episode  427 - score  -78.50062574581514 - average score  -309.0722064857047 - buffer size 116686 - timestep  317\n",
      "Episode  428 - score  -663.6527584090514 - average score  -314.487260753507 - buffer size 118622 - timestep  1936\n",
      "Episode  429 - score  -331.131963273285 - average score  -312.82529141411635 - buffer size 119808 - timestep  1186\n",
      "Episode  430 - score  -376.9215203012965 - average score  -312.9924942654727 - buffer size 120795 - timestep  987\n",
      "Episode  431 - score  -387.8980300402514 - average score  -314.20921502419964 - buffer size 121472 - timestep  677\n",
      "Episode  432 - score  -461.08035205755937 - average score  -314.8252244031571 - buffer size 121922 - timestep  450\n",
      "Episode  433 - score  -58.788915129954255 - average score  -312.6962080248453 - buffer size 122437 - timestep  515\n",
      "Episode  434 - score  -203.98886546755614 - average score  -311.82914652664306 - buffer size 123264 - timestep  827\n",
      "Episode  435 - score  1.4913900870594574 - average score  -309.8720434010535 - buffer size 123496 - timestep  232\n",
      "Episode  436 - score  -242.8136081914151 - average score  -309.8945689145907 - buffer size 124202 - timestep  706\n",
      "Episode  437 - score  -81.82236850926064 - average score  -308.6343771698248 - buffer size 124588 - timestep  386\n",
      "Episode  438 - score  -159.53683505634555 - average score  -308.03378546641756 - buffer size 125210 - timestep  622\n",
      "Episode  439 - score  -220.7634200930022 - average score  -305.27507807447927 - buffer size 125462 - timestep  252\n",
      "Episode  440 - score  -286.78054756322547 - average score  -305.5901210349297 - buffer size 125979 - timestep  517\n",
      "Episode  441 - score  -406.80612005837656 - average score  -305.90198155406654 - buffer size 126617 - timestep  638\n",
      "Episode  442 - score  114.00068803410913 - average score  -301.4294539350705 - buffer size 127859 - timestep  1242\n",
      "Episode  443 - score  -313.8035196161829 - average score  -298.0545740005978 - buffer size 128498 - timestep  639\n",
      "Episode  444 - score  -75.86078757009378 - average score  -293.48700975126735 - buffer size 129126 - timestep  628\n",
      "Episode  445 - score  -262.1159067087383 - average score  -292.8558208444916 - buffer size 129591 - timestep  465\n",
      "Episode  446 - score  82.55547854833391 - average score  -294.0552341540907 - buffer size 131739 - timestep  2148\n",
      "Episode  447 - score  -321.61799317901443 - average score  -294.393401608915 - buffer size 132318 - timestep  579\n",
      "Episode  448 - score  -39.572612405000896 - average score  -293.34957232901496 - buffer size 132559 - timestep  241\n",
      "Episode  449 - score  -362.1370416837791 - average score  -296.0985420273436 - buffer size 133361 - timestep  802\n",
      "Episode  450 - score  -169.21914891909748 - average score  -293.7558242953364 - buffer size 134136 - timestep  775\n",
      "Episode  451 - score  200.61030086404526 - average score  -289.8837360044869 - buffer size 134930 - timestep  794\n",
      "Episode  452 - score  -270.0254958840194 - average score  -288.4092476245185 - buffer size 135303 - timestep  373\n",
      "Episode  453 - score  -308.3118181479313 - average score  -288.91230014105264 - buffer size 136319 - timestep  1016\n",
      "Episode  454 - score  -254.66511171633576 - average score  -288.28566487496505 - buffer size 136551 - timestep  232\n",
      "Episode  455 - score  -434.37238870809574 - average score  -289.13806579610554 - buffer size 137724 - timestep  1173\n",
      "Episode  456 - score  -479.1880190786488 - average score  -291.21565527298236 - buffer size 139533 - timestep  1809\n",
      "Episode  457 - score  -372.54496079803 - average score  -292.628221781403 - buffer size 140347 - timestep  814\n",
      "Episode  458 - score  -70.03419546767003 - average score  -292.6544357470961 - buffer size 142982 - timestep  2635\n",
      "Episode  459 - score  -309.5104411532735 - average score  -293.2124754386491 - buffer size 143790 - timestep  808\n",
      "Episode  460 - score  -362.3603876864649 - average score  -294.50428906071187 - buffer size 144855 - timestep  1065\n",
      "Episode  461 - score  -383.89451064989527 - average score  -296.3584796311679 - buffer size 146256 - timestep  1401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m next_state \u001b[38;5;241m=\u001b[39m next_state\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, state_size)\n\u001b[1;32m     19\u001b[0m agent\u001b[38;5;241m.\u001b[39mstore_data(state, action, reward, next_state, done)\n\u001b[0;32m---> 20\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# if time_step > 1000:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     print('Exit this episode because landing takes too long')\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m     24\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "Cell \u001b[0;32mIn[10], line 113\u001b[0m, in \u001b[0;36mAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     Q_value_next_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_target(tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39msqueeze(next_states), actions_next_states], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    111\u001b[0m     y \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m Q_value_next_states \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones)\n\u001b[0;32m--> 113\u001b[0m     Q_value_current_states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    114\u001b[0m     critic_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(y \u001b[38;5;241m-\u001b[39m Q_value_current_states))\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape2:\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/keras/src/engine/training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    588\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:60\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_handler\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_traceback_filtering_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:47\u001b[0m, in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebugging.is_traceback_filtering_enabled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Check whether traceback filtering is currently enabled.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m  See also `tf.debugging.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    was called).\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ENABLE_TRACEBACK_FILTERING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# training\n",
    "env = gym.make(\"LunarLander-v2\", continuous=True)\n",
    "agent = Agent(state_size, action_size)\n",
    "score_history = []\n",
    "avg_score_history = []\n",
    "n_episodes = 20000\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state[0], [1, state_size])\n",
    "    time_step = 0  # to count number of steps the ship takes to land\n",
    "    while not done:\n",
    "        time_step += 1\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state = next_state.reshape(1, state_size)\n",
    "        agent.store_data(state, action, reward, next_state, done)\n",
    "        agent.learn()\n",
    "        # if time_step > 1000:\n",
    "        #     print('Exit this episode because landing takes too long')\n",
    "        #     break\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        \n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "    avg_score_history.append(avg_score)\n",
    "    print('Episode ', i, '- score ', score, '- average score ', avg_score, '- buffer size', len(agent.buffer), '- timestep ', time_step )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", continuous=True, render_mode='human')\n",
    "state = env.reset()\n",
    "state = np.reshape(state[0], [1, state_size])\n",
    "done = False\n",
    "score = 0\n",
    "while not done:\n",
    "    action = agent.select_action(state, evaluate=True)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "    next_state = next_state.reshape(1, state_size)\n",
    "    \n",
    "    state = next_state\n",
    "    score += reward\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(action_size=action_size, state_size=state_size)\n",
    "state = env.reset()\n",
    "state = np.reshape(state[0], [1, state_size])\n",
    "done = False\n",
    "score = 0\n",
    "for i in range(100):\n",
    "    env.render()\n",
    "    # select action\n",
    "    action = agent.select_action(state)\n",
    "    # perform the action\n",
    "    next_state, reward, done, _, _= env.step(action)\n",
    "    # insert data to the buffer\n",
    "    agent.store_data(state, action, reward, next_state, done)\n",
    "    # update the score\n",
    "    score += reward\n",
    "    # move to the next state\n",
    "    next_state = np.reshape(next_state, [1, state_size])\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = random.sample(agent.buffer, min(agent.buffer_size, agent.batch_size))\n",
    "states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "\n",
    "# convert to tensor, we want action to be integer\n",
    "states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
    "rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "dones = tf.convert_to_tensor(dones, dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape1:\n",
    "    actions_next_states = agent.actor_target(tf.squeeze(next_states))\n",
    "    Q_value_next_states = tf.squeeze(agent.critic_target(tf.concat([tf.squeeze(next_states), actions], axis=1)))\n",
    "    y = rewards + agent.gamma * Q_value_next_states * (1 - dones)\n",
    "    \n",
    "    Q_value_current_states = tf.squeeze(agent.critic_main(tf.concat([tf.squeeze(states), actions], axis=1)))\n",
    "    critic_loss = tf.reduce_mean(tf.square(y - Q_value_current_states))\n",
    "    \n",
    "with tf.GradientTape() as tape2:\n",
    "    new_actions = agent.actor_main(tf.squeeze(states))\n",
    "    actor_loss = tf.squeeze(agent.critic_main(tf.concat([tf.squeeze(states), new_actions], axis=1)))\n",
    "    actor_loss = - tf.reduce_mean(actor_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads1 = tape1.gradient(critic_loss, agent.critic_main.trainable_variables)\n",
    "grads2 = tape2.gradient(actor_loss, agent.actor_main.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor_main(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dqn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
